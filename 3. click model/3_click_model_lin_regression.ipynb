{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import  RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import pickle\n",
        "from google.cloud import bigquery\n",
        "import math\n",
        "import re\n",
        "#!pip install xgboost\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "num_folds = 4\n",
        "from nltk import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "#!pip install gensim\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.stem import PorterStemmer \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "metadata": {
        "id": "b8SEBElGgyc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "762050a5-abe5-44b7-f6d8-318e9946726c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wBtHBx7ygl4Y"
      },
      "outputs": [],
      "source": [
        "def click_model(df_ip,num_pos=[5,10,15], model = 'lr'):\n",
        "    '''\n",
        "    Objective:\n",
        "    * A click model is used for obtaining a relationship between impressions at different imp_positions and total click\n",
        "    * The predicted clicks from the model used in conjunction with actual clicks to obtain a relevancy score\n",
        "    * Relevance score = CEIL(4 * (actual clicks/predicted clicks))\n",
        "    \n",
        "    Input parameters:\n",
        "    df_ip: Input dataframe\n",
        "    num_pos: positions upto which the imp_postions to be considered while building click model\n",
        "    model: type of model  - 'lr' = linear regression, 'rf' = random forest\n",
        "    \n",
        "    Output:\n",
        "    * A dataframe containing the accuracy results for each of num_pos\n",
        "    * Output dataframe containing the predicted clicks\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    \n",
        "    #df_results = pd.DataFrame(columns=['imp_positions','train_rmse','test_rmse','train_r2','test_r2','train_MAPE','test_MAPE'])\n",
        "    df_results = pd.DataFrame(columns=['imp_positions','train_rmse','train_r2','train_MAPE'])\n",
        "    \n",
        "    for i in num_pos:\n",
        "        result = []\n",
        "        df = df_ip[df_ip['imp_position']<=i]\n",
        "        df.reset_index(drop=True,inplace=True)\n",
        "        df[['imp_position','total_impressions','total_clicks']] = df[['imp_position','total_impressions','total_clicks']].astype(int)\n",
        "        df_pivot = df.pivot_table(index=['imp_path','sku'],values = 'total_impressions', columns= 'imp_position' ).fillna(0).reset_index()\n",
        "        click_by_item_pos = df.groupby(['imp_path','sku'],as_index=False)['total_clicks'].sum()\n",
        "        df_pivot = df_pivot.merge(click_by_item_pos, on = ['imp_path','sku'],how='left')\n",
        "        df_pivot.sort_values(['imp_path','total_clicks'], ascending=[True,False],inplace=True)\n",
        "\n",
        "        df_pivot.reset_index(drop = True, inplace=True)\n",
        "        df_train = df_pivot[df_pivot.columns[2:]]\n",
        "\n",
        "        # separate the independent and target variable \n",
        "        train_X = df_train.drop(columns=['total_clicks'],axis=1)\n",
        "        train_Y = df_train['total_clicks']\n",
        "        \n",
        "        #for testing\n",
        "        #train_x, test_x, train_y, test_y = train_test_split(train_X, train_Y,test_size=0.25,random_state=0)    \n",
        "        \n",
        "        # create an object of the LinearRegression Model\n",
        "        if model == 'lr':\n",
        "            click_model = LinearRegression()\n",
        "\n",
        "        # fit the model with the training data\n",
        "            click_model.fit(train_X, train_Y)\n",
        "\n",
        "        # predict the target on train and test data\n",
        "         \n",
        "            predict_train = click_model.predict(train_X)\n",
        "            #predict_test  = click_model.predict(test_x)\n",
        "            \n",
        "        elif model== 'rf':\n",
        "            click_model = RandomForestRegressor(n_estimators=200, max_depth=10)\n",
        "            # fit the model with the training data\n",
        "            click_model.fit(train_X, train_Y)\n",
        "            # predict the target on train and test data \n",
        "            \n",
        "            predict_train = click_model.predict(train_X)\n",
        "            #predict_test  = click_model.predict(test_x)\n",
        "            \n",
        "        \n",
        "        result.append(i)\n",
        "        result.append(mean_squared_error(train_Y, predict_train)**(0.5))\n",
        "        #result.append(mean_squared_error(test_y, predict_test)**(0.5))\n",
        "        result.append(r2_score(train_Y, predict_train))\n",
        "        #result.append(r2_score(test_y, predict_test))\n",
        "        result.append(MAPE(train_Y,predict_train))\n",
        "        #result.append(MAPE(test_y,predict_test))\n",
        "        df_results.loc[len(df_results)] = result\n",
        "    \n",
        "    relevance_df = pd.concat([df_pivot,pd.DataFrame(predict_train,columns=['predicted'])],axis=1)\n",
        "    return click_model,df_results,relevance_df\n",
        "\n",
        "\n",
        "def MAPE(y_act,y_pred):\n",
        "    y_act = np.array(y_act)\n",
        "    y_pred = np.array(y_pred)\n",
        "    acc = []\n",
        "    for i in range(len(y_act)):\n",
        "        if (y_act[i] !=0):\n",
        "            acc.append(np.round((abs(y_act[i]-y_pred[i])/y_act[i])*100))\n",
        "    return np.round(((sum(acc)/len(acc))/100),2)\n",
        "\n",
        "\n",
        "def click_model_scoring(df_ip,model,num_pos=45):\n",
        "    '''\n",
        "    Objective:\n",
        "    * Click model for scoring\n",
        "    \n",
        "    Input parameters:\n",
        "    df_ip: Input dataframe\n",
        "    num_pos: positions upto which the imp_postions to be considered while building click model\n",
        "    model: trained click model\n",
        "    \n",
        "    Output:\n",
        "    * Output dataframe containing the predicted clicks\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    df = df_ip[df_ip['imp_position']<=num_pos]\n",
        "    df.reset_index(drop=True,inplace=True)\n",
        "    df_pivot = df.pivot_table(index=['imp_path','sku'],values = 'total_impressions', columns= 'imp_position' ).fillna(0).reset_index()\n",
        "    click_by_item_pos = df.groupby(['imp_path','sku'],as_index=False)['total_clicks'].sum()\n",
        "    df_pivot = df_pivot.merge(click_by_item_pos, on = ['imp_path','sku'],how='left')\n",
        "    df_pivot.sort_values(['imp_path','total_clicks'], ascending=[True,False],inplace=True)\n",
        "\n",
        "    df_pivot.reset_index(drop = True, inplace=True)\n",
        "    df_test = df_pivot[df_pivot.columns[2:]]\n",
        "\n",
        "    # separate the independent and target variable \n",
        "    test_X = df_test.drop(columns=['total_clicks'],axis=1)\n",
        "    test_Y = df_test['total_clicks']\n",
        "\n",
        "    predict_test  = model.predict(test_X)\n",
        "\n",
        "    return pd.concat([df_pivot,pd.DataFrame(predict_test,columns=['predicted'])],axis=1)    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def sort_and_process_relevance_data(relevance_df,pos=50):\n",
        "    \n",
        "    '''\n",
        "    objective: \n",
        "    Process the output of click model so that it is ready to be joined with feature set\n",
        "    \n",
        "    Input parameters:\n",
        "    Output of click model\n",
        "    \n",
        "    Output:\n",
        "    Processed dataframe\n",
        "    '''\n",
        "    \n",
        "    relevance_df['ratio'] = np.round((relevance_df['total_clicks']/relevance_df['predicted']),3)\n",
        "    #Sorting the output df based on query and ratio\n",
        "    relevance_df['total_imps'] = relevance_df.iloc[:,2:pos+2].sum(axis=1)\n",
        "    if pos>=10:\n",
        "        relevance_df['total_imps_1_10'] = relevance_df.iloc[:,2:11].sum(axis=1)\n",
        "    else:\n",
        "        relevance_df['total_imps_1_10'] = 0\n",
        "    \n",
        "    if pos>=20:\n",
        "        relevance_df['total_imps_10_20'] = relevance_df.iloc[:,11:21].sum(axis=1)\n",
        "    else:\n",
        "        relevance_df['total_imps_10_20'] = 0\n",
        "        \n",
        "    if pos>=30:\n",
        "        relevance_df['total_imps_20_30'] = relevance_df.iloc[:,21:31].sum(axis=1)\n",
        "    else:\n",
        "        relevance_df['total_imps_20_30'] = 0\n",
        "        \n",
        "    if pos>=40:\n",
        "        relevance_df['total_imps_30_40'] = relevance_df.iloc[:,31:41].sum(axis=1)\n",
        "    else:\n",
        "        relevance_df['total_imps_30_40'] = 0\n",
        "        \n",
        "    if pos==50:\n",
        "        relevance_df['total_imps_40_50'] = relevance_df.iloc[:,41:50].sum(axis=1)\n",
        "    else:\n",
        "        relevance_df['total_imps_40_50'] = 0 \n",
        "        \n",
        "    relevance_df = relevance_df.sort_values(['imp_path','ratio'],ascending=[True,False])[['imp_path','sku','total_clicks','total_imps','total_imps_1_10',\n",
        "                                                                                          'total_imps_10_20','total_imps_20_30','total_imps_30_40','total_imps_40_50','predicted','ratio']]\n",
        "    \n",
        "    OL_detection = relevance_df.groupby(['imp_path'],as_index=False)['ratio'].quantile(0.95).rename({'ratio':'quantile_95_ratio'},axis=1)\n",
        "    relevance_df = relevance_df.merge(OL_detection,on='imp_path',how='left')\n",
        "    relevance_df = relevance_df[relevance_df['ratio']<=relevance_df['quantile_95_ratio']]\n",
        "    relevance_df.reset_index(drop=True,inplace=True)\n",
        "    temp = relevance_df.groupby(['imp_path'],as_index=False)['ratio'].max().rename({'ratio':'max_ratio'},axis=1)\n",
        "    relevance_df = relevance_df.merge(temp,on=['imp_path'])\n",
        "    relevance_df['relevance_score'] = np.ceil(5*(relevance_df['ratio']/relevance_df['max_ratio']))\n",
        "    #relevance_df = relevance_df[['imp_path','sku','total_clicks','ratio','relevance_score']]\n",
        "    relevance_df = relevance_df[relevance_df['relevance_score']>=0]\n",
        "    return relevance_df\n",
        "\n",
        "\n",
        "def relevance_feature_join(df_feature,relevance_df):\n",
        "    '''\n",
        "    Objective:\n",
        "    Joining the product feature set with processed click-model output data\n",
        "    \n",
        "    Input parameters:\n",
        "    \n",
        "    df_feature= feature set dataframe\n",
        "    relevance_df = processed output of click-model\n",
        "    \n",
        "    Output:\n",
        "    Combined dataframe\n",
        "    \n",
        "    '''\n",
        "    df = relevance_df.merge(df_feature,left_on='sku',right_on='sku_config',how='left')\n",
        "    df.dropna(inplace=True)\n",
        "    temp = df.groupby(['imp_path'],as_index=False)['sku'].nunique().sort_values('sku',ascending=False)\n",
        "    fin_training_queries = list(temp[temp['sku']>=5]['imp_path'])\n",
        "    return df[df['imp_path'].isin(fin_training_queries)].reset_index(drop=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Inputs\n",
        "df_query1 =  pd.read_pickle('drive/MyDrive/Training Data/stage 1/df_query1.pkl')\n",
        "df_feature = pd.read_csv('drive/MyDrive/Training Data/stage 2/cleaned_prod_feature_set.csv')\n",
        "\n",
        "#Initial filtering of data before click model\n",
        "#Top queries with max clicks\n",
        "temp = df_query1.groupby(['imp_path'],as_index=False)['total_clicks'].sum().sort_values('total_clicks',ascending=False).reset_index(drop=True)\n",
        "exclusion = ['-','/','cart']\n",
        "temp = temp[~temp['imp_path'].isin(exclusion)]\n",
        "temp['cum_sum_clicks'] = temp['total_clicks'].cumsum()\n",
        "temp['contribution_to_overall_clicks'] = (temp['cum_sum_clicks']/temp['cum_sum_clicks'].max())\n",
        "\n",
        "queries = list(temp[temp['contribution_to_overall_clicks']<=0.90]['imp_path'].unique())\n",
        "\n",
        "temp = df_query1.groupby(['imp_path','sku'],as_index=False)['total_clicks'].sum().sort_values(['imp_path','total_clicks'],ascending=[False,False]).reset_index(drop=True)\n",
        "temp = temp[temp['imp_path'].isin(queries)]\n",
        "temp['click_cumsum_query'] = temp.groupby(['imp_path'],as_index=False)['total_clicks'].cumsum()\n",
        "temp = temp.merge(temp.groupby(['imp_path'],as_index=False)['click_cumsum_query'].max().rename({'click_cumsum_query':'grand_total_click_query'},axis=1),on=['imp_path'])\n",
        "temp['perc_contribution'] = temp['click_cumsum_query']/temp['grand_total_click_query']\n",
        "temp = temp[(temp['perc_contribution']<0.9)&(temp['total_clicks'] > 0)][['imp_path','sku']].drop_duplicates()\n",
        "\n",
        "df1 = df_query1.merge(temp,on=['imp_path','sku'])\n",
        "df1['imp_position'] = df1['imp_position'].astype(np.int64)\n",
        "\n",
        "#Running click model\n",
        "click__through_model,accuracy, relevance_df = click_model(df1,num_pos=[50], model = 'lr')\n",
        "print(relevance_df.shape)\n",
        "print(accuracy)\n",
        "\n",
        "relevance_df2 = sort_and_process_relevance_data(relevance_df,pos=50)\n",
        "\n",
        "\n",
        "df2 = relevance_feature_join(df_feature,relevance_df2)\n",
        "\n",
        "#Outputs\n",
        "pickle.dump(click__through_model, open('drive/MyDrive/Training Data/stage 3/click_through_model.pkl', 'wb'))\n",
        "relevance_df.to_csv('drive/MyDrive/Training Data/stage 3/unprocessed_click_model_op_ts.pkl')\n",
        "relevance_df2.to_csv('drive/MyDrive/Training Data/stage 3/processed_click_model_op_ts.csv')\n",
        "df2.to_csv('drive/MyDrive/Training Data/stage 3/relevance_feature_added_ts.csv')"
      ],
      "metadata": {
        "id": "TKrXM_Kd0-kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b924956-9ac7-463c-adb9-5bdcfd25bafd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(248539, 54)\n",
            "   imp_positions  train_rmse  train_r2  train_MAPE\n",
            "0           50.0   23.522968  0.523779        1.51\n"
          ]
        }
      ]
    }
  ]
}